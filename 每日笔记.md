roslaunch cartographer_ros lidar.launch

[ERROR] [1519539033.564366334]: filter time older than odom message buffer
*********
```cpp
void ld_compute_cartesian(LDP ld)
{
    int i;
    for(i=0;i<ld->nrays;i++)
    {
        double x = cos(ld->theta[i]) * ld->readings[i];
        double y = sin(ld->theta[i]) * ld->readings[i];

        ld->points[i].p[0] = x, 
        ld->points[i].p[1] = y;
        ld->points[i].rho = GSL_NAN;
        ld->points[i].phi = GSL_NAN;
    }
}


void ld_compute_world_coords(LDP ld, const double *pose)
{
    double pose_x = pose[0];
    double pose_y = pose[1];
    double pose_theta = pose[2];
    double cos_theta = cos(pose_theta); 
    double sin_theta = sin(pose_theta);
    const int nrays = ld->nrays ;

    point2d * points = ld->points;
    point2d * points_w = ld->points_w;
    int i;
    for(i=0; i<nrays; i++)
    {
        if(!ld_valid_ray(ld,i))
            continue;
        double x0 = points[i].p[0],  y0 = points[i].p[1]; 
         // 省略: 判断x,y是否是nan
        // 算法第一步,获得帧yt的激光点在y(t-1)中的坐标
        points_w[i].p[0] = cos_theta * x0 -sin_theta*y0 + pose_x;
        points_w[i].p[1] = sin_theta * x0 +cos_theta*y0 + pose_y;
    }
    for(i=0;i<nrays;i++)
    {
        double x = points_w[i].p[0];
        double y = points_w[i].p[1];
        points_w[i].rho = sqrt( x*x+y*y);
        points_w[i].phi = atan2(y, x);
    }
}
```
********
```cpp
for (int j = 0; j < n ; j++)
    single_ldp->theta[j] = scan[i].min_angle + j * scan[i].angle_increment;
single_ldp->min_theta = single_ldp->theta[0];
single_ldp->max_theta = single_ldp->theta[n-1];
```
std::numeric_limits <float>::quiet_NaN ();可以得到浮点型的nan
************
```cpp
// Compute laser_sens's points in laser_ref's coordinates
//ld是params的laser_sens  pose就是params的first guess,全是0
void ld_compute_world_coords(LDP ld, const double *pose)
{
    double pose_x = pose[0];
    double pose_y = pose[1];
    double pose_theta = pose[2];
    double cos_theta = cos(pose_theta); 
    double sin_theta = sin(pose_theta);
    const int nrays = ld->nrays ;

    point2d * points = ld->points;
    point2d * points_w = ld->points_w;
    int i;
    for(i=0;i<nrays;i++)
    {
        if(!ld_valid_ray(ld,i)) continue;
        double x0 = points[i].p[0], 
               y0 = points[i].p[1];
        
        points_w[i].p[0] = cos_theta * x0 - sin_theta*y0 + pose_x;
        points_w[i].p[1] = sin_theta * x0 + cos_theta*y0 + pose_y;

        double x = points_w[i].p[0];
        double y = points_w[i].p[1];
        points_w[i].rho = sqrt( x*x+y*y);
        points_w[i].phi = atan2(y, x);
    }
}
```

laser_scan_matcher，首先尝试一下两帧激光匹配,当时我把 processScan函数重构了一下, 现在想想完全没必要．把imu和odom都关掉后,只凭scan就能两帧激光匹配,可以使用这个包作为初始化位姿,代替里程计不准的情况,时间长了会有累计误差,后期用amcl定位,加其他传感器.
*******
技巧：
```cpp
  std::string tf_error;
  // we need to make sure that the transform between the robot base frame and the global frame is available
  while (ros::ok()
      && !tf_.waitForTransform(global_frame_, robot_base_frame_, ros::Time(), ros::Duration(0.1), ros::Duration(0.01),
                               &tf_error))
  {
    ros::spinOnce();
    if (last_error + ros::Duration(5.0) < ros::Time::now())
    {
      ROS_WARN("Timed out waiting for transform from %s to %s to become available before running costmap, tf error: %s",
               robot_base_frame_.c_str(), global_frame_.c_str(), tf_error.c_str());
      last_error = ros::Time::now();
    }
    // The error string will accumulate and errors will typically be the same, so the last
    // will do for the warning above. Reset the string here to avoid accumulation.
    tf_error.clear();
  }
```
检查全局和局部代价地图所用的参数
**********
雷达深度传感器，基于极坐标，可以持续的读取各个离散角度方向的深度。所谓地图配准问题，就是根据机器人的传感器测量数值来计算机器人的位姿，以此最好的适配地图。

目标函数如下，寻找最佳位姿p
![公式.png](https://i.loli.net/2020/05/25/BUztfKQFXalj4WI.png)
函数m(x,y)代表地图空闲或不空闲的，位姿p包含位置(x,y)及朝向p_theta，r_theta代表雷达不同角度的射线，函数delta表示从地图中获取当前位姿p下的地图数值。

直接求偏导什么的，计算量太大，不切实际。接下来我们将用粒子滤波算法，求解上述目标函数。
*********************
机器人移动时，机器人位置在变化，激光雷达的位置也在变化，所以每一帧的雷达数据的坐标系都不同，需要将它们统一到同一个坐标系下。雷达数据的特征提取和匹配是机器人的初定位。
***********
`gmap_pose`应当是不同时间戳时，雷达扫描扇形的中心(包含角度)

在odom坐标系中的坐标。排除掉所有激光距离小于range_min的值，这里**是否能优化？**
`reading.setPose(gmap_pose);`解释存疑
*********
`PointAccumulator`定义在smmap.h

​   Processscan函数：processscan函数在gridslamprocessor.cpp中，首先获取当前的位姿，然后在从里程计运动模型获取位姿，这里调用drawFromMotion函数，这个函数在motionmodel.cpp中.因为有这步，所以特别依赖里程计信息

当前位姿与上一次位姿做差，计算做累计角度偏差和位移偏差。利用激光雷达测得距离做得分处理。非首帧调用scanMatch，upDateTreeWeight,resample。首帧则调用invalidActiveArea,computeActiveArea,registerScan。

地图更新updateMap()得到最优的粒子，按照他的扫描数据，利用占据栅格地图算法，更新地图。
***********
/lib/ufw/register_service

for循环显然可以用OpenMP进行并行化,github上有OpenMP优化的gmapping


/*
里程计运动模型
p       表示粒子估计的最优位置(机器人上一个时刻的最优位置)
pnew    表示里程计算出来的新的位置
pold    表示里程计算出来的旧的位置(即上一个里程计的位置)
*/
```cpp
OrientedPoint 
MotionModel::drawFromMotion(const OrientedPoint& p, const OrientedPoint& pnew, const OrientedPoint& pold) const
{
    double sxy=0.3*srr;
     // 计算出pnew 相对于 pold走了多少距离
     // 这里的距离表达是相对于车身坐标系来说的
    OrientedPoint delta=absoluteDifference(pnew, pold);
    
    /*初始化一个点*/
    OrientedPoint noisypoint(delta);
    
    /*走过的X轴方向的距离加入噪声*/
    noisypoint.x+=sampleGaussian(srr*fabs(delta.x)+str*fabs(delta.theta)+sxy*fabs(delta.y));
    
    /*走过的Y轴方向的距离加入噪声*/
    noisypoint.y+=sampleGaussian(srr*fabs(delta.y)+str*fabs(delta.theta)+sxy*fabs(delta.x));
    
    /*走过的Z轴方向的距离加入噪声*/
    noisypoint.theta+=sampleGaussian(stt*fabs(delta.theta)+srt*sqrt(delta.x*delta.x+delta.y*delta.y));
    
    /*限制角度的范围为 -π～π  */
    noisypoint.theta=fmod(noisypoint.theta, 2*M_PI);
    if (noisypoint.theta>M_PI)
        noisypoint.theta-=2*M_PI;
    
    /*把加入了噪声的值 加到粒子估计的最优的位置上，得到新的位置(根据运动模型推算出来的位置)*/
    return absoluteSum(p,noisypoint);
}
```
***********
运行：`rosrun depthimage_to_laserscan depthimage_to_laserscan`

源码中的调用关系如下：
`DepthImageToLaserScan.cpp`中的main函数
                丨
                丨
`DepthImageToLaserScanROS` 构造函数
                丨
                丨
`pub_ = n.advertise<sensor_msgs::LaserScan>("scan", 10, boost::bind(&DepthImageToLaserScanROS::connectCb, this, _1), boost::bind(&DepthImageToLaserScanROS::disconnectCb, this, _1));`
                丨
                丨
`DepthImageToLaserScanROS::connectCb`
                丨
                丨
`subscribeCamera("image")`，这里应当改为`/camera/depth/image_raw`，或者用rosparam机制修改。


`sensor_msgs/LaserScan` overlayed in color on the `sensor_msgs/Image`. 红色是靠近摄像头，紫色远离摄像头。

`depthimage_to_laserscan`处理的是深度图(float encoded meters 或者 uint16 encoded millimeters for OpenNI devices)，根据提供的参数产生2D雷达scan. 它使用的是<font size =4,color=blue>lazy订阅机制</font> 直到其他节点订阅`scan`，才会订阅`image`或者`camera_info`.也就是上面的advertise函数中的bind占位符做参数。

生成的scan参数如下：
[](https://i.loli.net/2020/06/03/CkWzPvnbJDyVqOt.png)

参考：[depthimage_to_laserscan](http://wiki.ros.org/depthimage_to_laserscan)
