roslaunch cartographer_ros lidar.launch
*********
```cpp
void ld_compute_cartesian(LDP ld)
{
    int i;
    for(i=0;i<ld->nrays;i++)
    {
        double x = cos(ld->theta[i]) * ld->readings[i];
        double y = sin(ld->theta[i]) * ld->readings[i];

        ld->points[i].p[0] = x, 
        ld->points[i].p[1] = y;
        ld->points[i].rho = GSL_NAN;
        ld->points[i].phi = GSL_NAN;
    }
}


void ld_compute_world_coords(LDP ld, const double *pose)
{
    double pose_x = pose[0];
    double pose_y = pose[1];
    double pose_theta = pose[2];
    double cos_theta = cos(pose_theta); 
    double sin_theta = sin(pose_theta);
    const int nrays = ld->nrays ;

    point2d * points = ld->points;
    point2d * points_w = ld->points_w;
    int i;
    for(i=0; i<nrays; i++)
    {
        if(!ld_valid_ray(ld,i))
            continue;
        double x0 = points[i].p[0],  y0 = points[i].p[1]; 
         // 省略: 判断x,y是否是nan
        // 算法第一步,获得帧yt的激光点在y(t-1)中的坐标
        points_w[i].p[0] = cos_theta * x0 -sin_theta*y0 + pose_x;
        points_w[i].p[1] = sin_theta * x0 +cos_theta*y0 + pose_y;
    }
    for(i=0;i<nrays;i++)
    {
        double x = points_w[i].p[0];
        double y = points_w[i].p[1];
        points_w[i].rho = sqrt( x*x+y*y);
        points_w[i].phi = atan2(y, x);
    }
}
```
********
```cpp
for (int j = 0; j < n ; j++)
    single_ldp->theta[j] = scan[i].min_angle + j * scan[i].angle_increment;
single_ldp->min_theta = single_ldp->theta[0];
single_ldp->max_theta = single_ldp->theta[n-1];
```
std::numeric_limits <float>::quiet_NaN ();可以得到浮点型的nan
************
```cpp
// Compute laser_sens's points in laser_ref's coordinates
//ld是params的laser_sens  pose就是params的first guess,全是0
void ld_compute_world_coords(LDP ld, const double *pose)
{
    double pose_x = pose[0];
    double pose_y = pose[1];
    double pose_theta = pose[2];
    double cos_theta = cos(pose_theta); 
    double sin_theta = sin(pose_theta);
    const int nrays = ld->nrays ;

    point2d * points = ld->points;
    point2d * points_w = ld->points_w;
    int i;
    for(i=0;i<nrays;i++)
    {
        if(!ld_valid_ray(ld,i)) continue;
        double x0 = points[i].p[0], 
               y0 = points[i].p[1];
        
        points_w[i].p[0] = cos_theta * x0 - sin_theta*y0 + pose_x;
        points_w[i].p[1] = sin_theta * x0 + cos_theta*y0 + pose_y;

        double x = points_w[i].p[0];
        double y = points_w[i].p[1];
        points_w[i].rho = sqrt( x*x+y*y);
        points_w[i].phi = atan2(y, x);
    }
}
```
*******
检查全局和局部代价地图所用的参数

雷达深度传感器，基于极坐标，可以持续的读取各个离散角度方向的深度。所谓地图配准问题，就是根据机器人的传感器测量数值来计算机器人的位姿，以此最好的适配地图。
*********************
机器人移动时，机器人位置在变化，激光雷达的位置也在变化，所以每一帧的雷达数据的坐标系都不同，需要将它们统一到同一个坐标系下。雷达数据的特征提取和匹配是机器人的初定位。
**********
八叉树地图特点
- 稀疏: 不需要对空间进行稠密切分
- 结构化: 方块排列固定,切分为八份
- 非直接索引查询

点云地图: 无序,因为它的点都是无序的,无法坐标索引查询;
*********
金坛河滨小学 0519－82837968

imu的偏航角在长时间移动后会有严重的漂移误差，只能定时校准


节点`cartographer_node`的信息如下：
```sh
Publications:
 * /constraint_list [visualization_msgs/MarkerArray]
 * /landmark_poses_list [visualization_msgs/MarkerArray]
 * /rosout [rosgraph_msgs/Log]
 * /scan_matched_points2 [sensor_msgs/PointCloud2]
 * /submap_list [cartographer_ros_msgs/SubmapList]
 * /tf [tf2_msgs/TFMessage]
 * /trajectory_node_list [visualization_msgs/MarkerArray]

Subscriptions:
 * /scan [sensor_msgs/LaserScan]
 * /tf [tf2_msgs/TFMessage]
 * /tf_static [tf2_msgs/TFMessage]

Services:
 * /cartographer_node/get_loggers
 * /cartographer_node/set_logger_level
 * /finish_trajectory
 * /start_trajectory
 * /submap_query
```

节点`cartographer_occupancy_grid_node`：
```sh
Publications:
 * /map [nav_msgs/OccupancyGrid]
 * /rosout [rosgraph_msgs/Log]

Subscriptions:
 * /submap_list [cartographer_ros_msgs/SubmapList]
```
***********
在rqt里查看`/camera/depth/image_rect_raw/compressed`，深度图无法显示，同时rqt终端里报警:
```
ImageView.callback_image() while trying to convert image from '16UC1' to 'rgb8' an exception was thrown (Image is wrongly formed: step < width * byte_depth * num_channels  or  640 != 640 * 2 * 1)
```

在rqt里查看`/camera/depth/image_rect_raw/theora`，同样没有深度图，但rqt不报警


在rqt查看RGB和红外的图像，只要选择theora，rqt终端都会报警:
```
[ WARN][/rqt_gui_cpp_node_25764] [TheoraSubscriber::internalCallback] line_170  [theora] Packet was not a Theora header
```
*********
D435i采用了即用型USB供电形式，不仅提供深度传感器模组，还配备了一个IMU单元（惯性测量单元，采用的博世BMI055）。凭借内置的IMU单元，结合视觉数据可实现6DoF追踪功能。其中，IMU将各种线性加速度计和陀螺仪数据结合，可检测X，Y，Z三轴的旋转和平移，以及俯仰、横摇等动作。D435i的2000万像素RGB摄像头和3D传感器可以30帧/秒的速度提供分辨率高达1280 × 720，或者以90帧/秒的速度提供848 × 480的较低分辨率。该摄像头具有全局快门，可以处理快速移动物体，室内室外皆可操作。深度距离在`0.1 m~10 m`之间，视场角度为85 × 58度

可以获得RGB图、左右红外摄像图、深度图、IMU数据，并且将深度图数据和RGB图进行对齐。左右红外相机进行测量深度，中间红外点阵投射器相当于补光灯，不打开也能测深度，只是效果不好；最右边的rgb相机用于采集彩色图片，最终可以将彩色视频流与深度流进行对齐.

`realsense_camera/IMUInfo` with the header.frame_id set to either `imu_accel` or `imu_gyro` to distinguish between `accel` and `gyro` info.
成员如下:
```
string frame_id
float64[12] data
float64[3] noise_variances
float64[3] bias_variances
```
********
标定Realsense D435i的内外参

realsense d435i包含两个红外相机、红外发射器、RGB相机和IMU四个模块，显然四个传感器的空间位置是不同的，我们在处理图像和IMU数据时需要将这些数据都放在统一的坐标系上去。比如我们用d435i运行vins，处理的图像和IMU数据都需要放在同一个坐标系下，因此需要标定IMU相对RGB相机的空间位置（包括旋转和位移）。
　　另外，相机固有参数比如焦距、畸变参数等以及IMU的零偏和scale系数等都需要提前知道。前者称为外参，后者称为内参，在运行程序前我们需要标定它们，不论程序是否有自标定功能，毕竟好的初始标定值对于自标定来说也是有利的。

标定顺序：**IMU标定 --> 相机标定 --> IMU+相机联合标定**.　这么设定顺序是因为最后一步IMU和相机的联合标定需要IMU和相机的内参


Kalibr可以解决以下的标定问题:

- 多相机标定: 一个相机系统的内外参标定，这几个相机没有全局性重叠的视角
- 视觉惯性标定(camera-IMU): IMU关于相机系统的时空间标定
- Rolling Shutter Camera calibration: full intrinsic calibration (projection, distortion and shutter parameters) of rolling shutter cameras

我们可以下载Kalibr源码编译生成可执行文件，也可以下载其CDE精简版包。这中间有个坑就是CDE精简包是没有办法标定彩色图片的，而D435输出的是彩色图。

## 安装Kalibr

1. 安装依赖项
```sh
sudo apt-get install python-pyx
sudo apt-get install python-setuptools
sudo apt-get install python-setuptools python-rosinstall ipython libeigen3-dev libboost-all-dev doxygen
sudo apt-get install ros-kinetic-vision-opencv ros-kinetic-image-transport-plugins ros-kinetic-cmake-modules python-software-properties software-properties-common libpoco-dev python-matplotlib python-scipy python-git python-pip ipython libtbb-dev libblas-dev liblapack-dev python-catkin-tools libv4l-dev
```
2. 源码放入工作空间进行编译，会花很长时间，所以编译命令要这样:
```sh
# 视情况取j8
catkin_make -DCMAKE_BUILD_TYPE=Release -j4
```


a. 标定板pattern尽量选择apriltag，尽量不要用纸质的；b. 选择合适的相机模型；c. 标定手法看看TUM的
*********
`ls -lht frames.pdf` 显示文件的详细信息，比如:
```sh
-rw-rw-r-- 1 zzp zzp 20K 6月  29 10:24 frames.pdf
```

`catkin_make -DCMAKE_BUILD_TYPE=Release -j4`
***********
bag文件包含tf信息，没有rosparam参数.


回放过程中按空格暂停

可以录制雷达和相机话题的bag或IMU和相机的bag，然后回放用来进行联合外参标定

默认模式下，rosbag play命令在公告每条消息后会等待0.2秒才真正开始发布bag文件中的消息。如果rosbag play在公告消息后立即发布，订阅器可能会接收不到几条最先发布的消息

等待时间可以通过`-d`选项来指定,比如等待10秒再播放bag: `rosbag play -d 10 realsense.bag`


以暂停的方式启动，防止跑掉数据：
```sh
rosbag play --pause record.bag
```

设置以0.5倍速回放，也就是以录制频率的一半回放：
```sh
rosbag play -r 0.5 record.bag
```

循环播放：
```sh
rosbag play -l record.bag
```

## rosbag compress

如果录制的bag很大，我们可以压缩它，默认的压缩格式是bz2：
```sh
rosbag compress xxx.bag
```

你也可以添加`-j`手动指定压缩格式为bz2：
```sh
rosbag compress -j xxx.bag
```

也可以使用LZ4来压缩数据：
```sh
rosbag compress --lz4 xxx.bag
```

解压缩：
```sh
rosbag decompress xxx.bag
```

如果同时回放两个单独的bag文件，则根据时间戳的间隔来播放。比如我先录制一个bag1，等待一个小时，然后录制另一个 bag2，那我在一起回放 bag1 和 bag2 时，实际是先回放bag1，然后等待1个小时才回放bag2
*********


参考: [Realsense D435i关闭IR结构光](https://blog.csdn.net/Hanghang_/article/details/103612300)
******
用imu_utils标定IMU

A ROS package tool to analyze the IMU performance. C++ version of Allan Variance Tool. The figures are drawn by Matlab, in scripts.

Actually, just analyze the Allan Variance for the IMU data. Collect the data while the IMU is Stationary, with a two hours duration.


1. 安装依赖项，不装之后的编译会报错： `sudo apt-get -y install libdw-dev`
2. 全局安装ceres库，因为`code_imu`依赖ceres。code_utils标定IMU的噪音密度和随机游走系数。　不要同时把imu_utils和code_utils一起放到src下进行编译。因为imu_utils 依赖 code_utils，原作者的CMakeLists写的不好，所以先编译code_utils再编译后者。
3. 在code_utils下面找到sumpixel_test.cpp，修改`#include "backward.hpp"`为`#include"code_utils/backward.hpp"`，再编译。
4. 让IMU静止不动两个小时，录制IMU的bag.
5. 标定

```sh
rosbag play -r 200　imu_utils/imu.bag
roslaunch imu_utils a3.launch
```
注意launch文件需要自己模仿现有的写一个:
```xml
<launch>
    <node pkg="imu_utils" type="imu_an" name="imu_an" output="screen">
        <param name="imu_topic" type="string" value= "/djiros/imu"/>
        <param name="imu_name" type="string" value= "A3"/>
        <param name="data_save_path" type="string" value= "$(find imu_utils)/data/"/>
        <param name="max_time_min" type="int" value= "120"/>
        <param name="max_cluster" type="int" value= "100"/>
    </node>
</launch>
```
max_time_min代表的是标定时间，这里的单位是分钟，意思是填10就是代表10分钟，至少录rosbag十分钟。


只用到其中四个参数：
```sh
Gyr:
   avg-axis:
      gyr_n: 3.1820671461855504e-03
      gyr_w: 3.0693398103399251e-05
Acc:
   avg-axis:
      acc_n: 2.6449533258549235e-02
      acc_w: 7.2111910796954259e-04
```
分别是陀螺仪和加速度计 随机游走和 高斯白噪声的平均值，是IMU噪声模型中的两种噪声


参考: [官方Github](https://github.com/gaowenliang/imu_utils)
[VIO标定IMU随机误差——Allan方差法](https://www.geek-share.com/detail/2798533390.html)